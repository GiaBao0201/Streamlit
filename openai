import os
import time
import threading
from google.cloud import speech, texttospeech, vision, translate_v2 as translate
from pydub import AudioSegment
from pygame import mixer
import RPi.GPIO as GPIO
import pigpio
import speech_recognition as sr
import requests

# Cấu hình biến môi trường cho Google Cloud
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/home/admin/Downloads/esp32-441714-19ff1efdb06f.json"

# Cấu hình GPIO
CHAT_BUTTON_PIN = 26
OCR_BUTTON_PIN = 12

GPIO.setmode(GPIO.BCM)
GPIO.setup(CHAT_BUTTON_PIN, GPIO.IN, pull_up_down=GPIO.PUD_UP)
GPIO.setup(OCR_BUTTON_PIN, GPIO.IN, pull_up_down=GPIO.PUD_UP)

# Khởi tạo mixer của Pygame
mixer.init(frequency=44100, size=-16, channels=1, buffer=512)

# Biến toàn cục
is_processing = False
ocr_text_global = ""
is_paused = False

pi = pigpio.pi()
if not pi.connected:
    print("AI Vision Reader không thể kết nối tới PIGPIO DAEMON. Thoát!")
    exit()


def play_audio(text, lang='vi', output_file='output.mp3', speed=1.1):
    """Đọc văn bản bằng giọng nói."""
    global is_paused
    client = texttospeech.TextToSpeechClient()

    synthesis_input = texttospeech.SynthesisInput(text=text)
    voice_params = {
        'vi': texttospeech.VoiceSelectionParams(language_code="vi-VN", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL),
        'en': texttospeech.VoiceSelectionParams(language_code="en-US", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)
    }
    voice = voice_params.get(lang, voice_params['vi'])
    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)

    response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)

    with open(output_file, "wb") as out:
        out.write(response.audio_content)

    sound = AudioSegment.from_file(output_file)
    sound_with_speed = sound.speedup(playback_speed=speed)
    sound_with_speed.export(output_file, format="mp3")

    mixer.music.load(output_file)
    mixer.music.play()

    while mixer.music.get_busy():
        if is_paused:
            mixer.music.pause()
            while is_paused:
                time.sleep(0.1)
            mixer.music.unpause()
        time.sleep(0.1)


def detect_language(text):
    """Phát hiện ngôn ngữ của văn bản."""
    translate_client = translate.Client()
    result = translate_client.detect_language(text)
    detected_language = result['language']
    print(f"Phát hiện ngôn ngữ: {detected_language}")
    return detected_language


def setup_google_speech_to_text():
    """Nhận diện giọng nói và chuyển thành văn bản."""
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()

    with microphone as source:
        print("Vui lòng đợi! Đang cân chỉnh micro...")
        recognizer.adjust_for_ambient_noise(source)
        print("Micro đã sẵn sàng. Vui lòng đặt câu hỏi...")
        audio = recognizer.listen(source)

    client = speech.SpeechClient()
    audio_content = audio.get_wav_data()
    audio_wav = speech.RecognitionAudio(content=audio_content)

    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=44100,
        language_code="vi-VN",
    )

    response = client.recognize(config=config, audio=audio_wav)
    for result in response.results:
        text = result.alternatives[0].transcript
        print(f"Nội dung: {text}")
        return text


def ask_chatgpt(prompt):
    """Gửi câu hỏi tới ChatGPT API."""
    api_key = "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"
    headers = {'Content-Type': 'application/json', 'Authorization': f'Bearer {api_key}'}
    data = {'model': 'gpt-4o', 'messages': [{'role': 'user', 'content': prompt}]}

    response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=data)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        print("Lỗi khi gọi API:", response.text)
        return None


def handle_chat_interaction():
    """Xử lý khi nhấn nút ChatGPT."""
    global ocr_text_global
    print("Bạn đã nhấn nút CHAT! Trợ lý đang chờ bạn...")

    play_audio("Xin chào! Tôi có thể giúp gì cho bạn?")
    try:
        speech_text = setup_google_speech_to_text()
        if not speech_text:
            play_audio("Bạn đang hỏi về vấn đề gì? Hãy thử nói cụ thể hơn nhé!")
            return

        print(f"Bạn nói: {speech_text}")
        combined_prompt = f"Nội dung OCR: {ocr_text_global}. Câu hỏi: {speech_text}"
        print(f"Gửi đến ChatGPT: {combined_prompt}")

        response = ask_chatgpt(combined_prompt)
        if not response:
            play_audio("Rất tiếc, câu hỏi của bạn nằm ngoài phạm vi hỗ trợ của tôi.")
        else:
            print(f"Phản hồi của ChatGPT: {response}")
            lang = detect_language(response)
            play_audio(response, lang)

    except sr.UnknownValueError:
        play_audio("Tôi không nghe rõ, bạn có thể nói lại cụ thể hơn không?")
    except Exception as e:
        print(f"Có lỗi xảy ra: {e}")


def take_picture():
    """Chụp ảnh bằng camera Raspberry Pi."""
    result = os.system('rpicam-jpeg --output test.jpg')
    return result == 0


def perform_ocr(image_path):
    """Thực hiện OCR trên ảnh đã chụp."""
    client = vision.ImageAnnotatorClient()
    with open(image_path, 'rb') as image_file:
        content = image_file.read()

    image = vision.Image(content=content)
    response = client.text_detection(image=image)
    texts = response.text_annotations
    if texts:
        return texts[0].description
    return ""


def handle_ocr_and_tts():
    """Xử lý OCR và đọc to nội dung."""
    global is_processing, ocr_text_global
    is_processing = True

    if take_picture():
        play_audio("Đã sẵn sàng.")
        ocr_text = perform_ocr("test.jpg")
        if ocr_text:
            print(f"Nội dung OCR: {ocr_text}")
            ocr_text_global = ocr_text
            lang = detect_language(ocr_text)
            play_audio(ocr_text, lang)
        else:
            play_audio("Vui lòng quét lại văn bản!")
    else:
        play_audio("Camera chưa sẵn sàng.")
    is_processing = False


def main():
    global is_paused
    print("Welcome to AI Vision Reader. Nhấn nút số 1 để đọc sách, nhấn nút số 2 để tương tác với trợ lý ảo.")
    last_chat_state = pi.read(CHAT_BUTTON_PIN)

    try:
        while True:
            chat_button_state = pi.read(CHAT_BUTTON_PIN)
            ocr_button_state = GPIO.input(OCR_BUTTON_PIN)

            if chat_button_state == 0 and last_chat_state == 1:
                handle_chat_interaction()

            if ocr_button_state == GPIO.LOW and not is_processing:
                print("Nhấn nút OCR. Bắt đầu OCR...")
                threading.Thread(target=handle_ocr_and_tts).start()

            last_chat_state = chat_button_state
            time.sleep(0.05)

    except KeyboardInterrupt:
        print("Chương trình AI Vision Reader bị ngắt kết nối.")
    finally:
        mixer.quit()
        GPIO.cleanup()
        pi.stop()


if __name__ == '__main__':
    main()
